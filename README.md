# AdversarialToolbox  
**å¯¹æŠ—æ”»å‡»ç”Ÿæˆä¸æ¨¡å‹é²æ£’æ€§è¯„ä¼°æ¡†æ¶**  

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-red)

ä¸€ç«™å¼è§£å†³æ–¹æ¡ˆï¼Œæ”¯æŒå¿«é€Ÿç”Ÿæˆå¯¹æŠ—æ ·æœ¬ã€è¯„ä¼°æ¨¡å‹è„†å¼±æ€§ï¼Œå¹¶æä¾›å¯è§†åŒ–åˆ†æå·¥å…·ã€‚

## ğŸš€ é¡¹ç›®èƒŒæ™¯  
æ·±åº¦ç¥ç»ç½‘ç»œçš„å¯¹æŠ—é²æ£’æ€§æ˜¯AIå®‰å…¨çš„æ ¸å¿ƒé—®é¢˜ã€‚ç°æœ‰å·¥å…·åº“å¸¸é¢ä¸´æ”»å‡»æ–¹æ³•å®ç°ä¸ä¸€è‡´ã€è¯„ä¼°æµç¨‹ç¢ç‰‡åŒ–ç­‰é—®é¢˜ã€‚AdversarialToolbox é€šè¿‡æ ‡å‡†åŒ–æ¥å£å’Œè‡ªåŠ¨åŒ–æµç¨‹ï¼Œå¸®åŠ©ç ”ç©¶è€…å’Œå¼€å‘è€…ï¼š  
- ğŸ” **å¿«é€Ÿå¤ç°**è®ºæ–‡ä¸­çš„æ”»å‡»æ–¹æ³•  
- âš¡ **é«˜æ•ˆè¯„ä¼°**æ¨¡å‹åœ¨å®é™…å¯¹æŠ—åœºæ™¯ä¸­çš„è¡¨ç°  
- ğŸ§© **æ— ç¼æ‰©å±•**è‡ªå®šä¹‰æ”»å‡»ç®—æ³•ä¸é˜²å¾¡ç­–ç•¥  

## âœ¨ åŠŸèƒ½ç‰¹æ€§  
| æ¨¡å—         | åŠŸèƒ½æè¿°                                                                 |  
|--------------|--------------------------------------------------------------------------|  
| **æ”»å‡»ç”Ÿæˆ** | æ”¯æŒFGSM/Poincare/Logit/CFMç­‰12+æ–¹æ³•ï¼Œæä¾›å®šå‘/éå®šå‘æ”»å‡»æ¨¡å¼                   |  
| **è¯„ä¼°åˆ†æ** | è‡ªåŠ¨åŒ–è®¡ç®—ASRã€ç½®ä¿¡åº¦åˆ†å¸ƒï¼Œç”ŸæˆL2/Lâˆæ‰°åŠ¨åˆ†ææŠ¥å‘Š                         |  
| **å¯è§†åŒ–**   | äº¤äº’å¼å¯¹æ¯”åŸå§‹æ ·æœ¬ä¸å¯¹æŠ—æ ·æœ¬ï¼Œæ”¯æŒçƒ­åŠ›å›¾æ˜¾ç¤ºå…³é”®æ‰°åŠ¨åŒºåŸŸ                 |  
| **éƒ¨ç½²æ”¯æŒ** | æä¾›ONNX/TensorRTå¯¼å‡ºæ¥å£ï¼Œæ”¯æŒè¾¹ç¼˜è®¾å¤‡å¯¹æŠ—æµ‹è¯•                          |  

## ğŸ›  å¿«é€Ÿå¼€å§‹ ï¼ˆä»¥DI-FGSMæ”»å‡»ä¸ºä¾‹ï¼‰
### å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```
### åœ¨configure.pyæ–‡ä»¶é‡Œé¢é…ç½®ç›¸å…³å‚æ•°
```python
#é…ç½®æ•°æ®é›†
victim_datasets = [('imagenet', '/home/zero/zero/split_dp/dataset/imagenet/new_adv_1k')]
#é…ç½®è¾“å‡ºè·¯å¾„
test_output_path = '/home/zero/zero/split_dp/dataset/imagenet/dtest_outputs'
#é€‰æ‹©æ”»å‡»æ–¹æ³•åŠå…¶å‚æ•°ï¼Œå¯ä»¥æ·»åŠ å¤šä¸ªæ”»å‡»æ–¹æ³•
baseline_attack_methods = {
    'DI-FGSM': {
        'max_iter': 10,            # iterations
        'decay_factor': 1.0,          # decay factor
        'eps': 0.07,    # perturbation
        'diversity_prob': 0.7,
        'feature_model': False,
    }
}
```
### ç”Ÿæˆå¯¹æŠ—æ ·æœ¬
```python
import torch
from model_zoo import ModelZoo
from dataset_zoo import DatasetZoo
from attacks.lbap import LBAP

### åˆå§‹åŒ–æ¨¡å‹ä¸æ•°æ®
model = ModelZoo().load('resnet50').cuda().eval()
dataset = DatasetZoo().load('imagenet_val', path='data/imagenet')


### å¯¹å•å¼ å›¾åƒç”Ÿæˆå¯¹æŠ—æ ·æœ¬
image, label = dataset[0]
image = image.unsqueeze(0).cuda()
target_label = 123  # å‡è®¾ç›®æ ‡ç±»åˆ«ä¸º123ï¼ˆéœ€æ ¹æ®å®é™…æ”»å‡»ç›®æ ‡è®¾ç½®ï¼‰

adv_image = attack(image, target_label)

### ä¿å­˜ç»“æœ
save_image(adv_image, 'results/lbap_adv.png')

### åœ¨ImageNetéªŒè¯é›†ä¸Šæµ‹è¯•ResNet50å¯¹LBAPæ”»å‡»çš„é²æ£’æ€§
python evaluate_attack.py \
  --model resnet50 \
  --attack lbap \
  --dataset imagenet_val \
  --eps 16 \
  --batch_size 32 \
  --output_dir ./results
```

---


## ğŸ”« æ”¯æŒçš„æ”»å‡»æ–¹æ³•  
| æ–¹æ³•åç§°       | æ ¸å¿ƒæ€æƒ³    | å¯åŠ¨æ–¹å¼ | å‚è€ƒæ–‡çŒ® |  
|----------------|----------|----------|--------------|  
| **DI-FGSM**  | ç»“åˆè¾“å…¥å¤šæ ·æ€§ï¼ˆéšæœºå˜æ¢ï¼‰å’Œè¿­ä»£ä¼˜åŒ–ï¼Œå¢å¼ºå¯¹æŠ—æ ·æœ¬çš„è¿ç§»æ€§ã€‚ | åœ¨configure.pyä¸­å¯åŠ¨DI-FGSM|1|
| **LINTDI-FGSM** | åœ¨DI-FGSMåŸºç¡€ä¸Šå¼•å…¥çº¿æ€§å™ªå£°ï¼Œè¿›ä¸€æ­¥æå‡å¯¹æŠ—æ ·æœ¬é²æ£’æ€§ã€‚ |åœ¨configure.pyä¸­å¯åŠ¨LINTDI-FGSM|2|
| **DDDI-FGSM**  | åŠ¨æ€è°ƒæ•´è¾“å…¥å¤šæ ·æ€§ç­–ç•¥ï¼Œè‡ªé€‚åº”ä¼˜åŒ–æ‰°åŠ¨ç”Ÿæˆã€‚ |åœ¨configure.pyä¸­å¯åŠ¨DDDI-FGSM|3|  
| **TI-FGSM**    |é€šè¿‡å¹³ç§»ä¸å˜æ€§ç”Ÿæˆæ‰°åŠ¨ï¼Œæå‡é»‘ç›’æ”»å‡»è¿ç§»æ€§ã€‚|åœ¨configure.pyä¸­å¯åŠ¨TI-FGSM|4|
| **LINTTI-FGSM** |ç»“åˆçº¿æ€§å™ªå£°å’Œå¹³ç§»ä¸å˜æ€§ï¼ˆTIï¼‰çš„æ··åˆæ”»å‡»æ–¹æ³•ã€‚|åœ¨configure.pyä¸­å¯åŠ¨LINTTI-FGSM|5|
| **ENSTI-FGSM**  |é›†æˆå¤šæ¨¡å‹æ¢¯åº¦å’Œå¹³ç§»ä¸å˜æ€§ï¼Œå¢å¼ºæ”»å‡»æ³›åŒ–æ€§ã€‚|åœ¨configure.pyä¸­å¯åŠ¨ENSTI-FGSM|6|
| **GTI-FGSM** |å¹¿ä¹‰å¹³ç§»ä¸å˜æ€§ï¼Œæ‰©å±•å¹³ç§»æ“ä½œèŒƒå›´ï¼ˆå¦‚æ—‹è½¬ã€ç¼©æ”¾ï¼‰ã€‚|åœ¨configure.pyä¸­å¯åŠ¨GTI-FGSM|7|
| **DDTI-FGSM** |åŠ¨æ€å¤šæ ·æ€§å¹³ç§»ä¸å˜æ”»å‡»ï¼Œç»“åˆåŠ¨æ€è¾“å…¥å’ŒTIç­–ç•¥ã€‚ |åœ¨configure.pyä¸­å¯åŠ¨DDTI-FGSM|8|
| **Poincare** |åŸºäºåºåŠ è±çƒæ¨¡å‹çš„å¯¹æŠ—æ”»å‡»ï¼Œä¼˜åŒ–é«˜ç»´æµå½¢ç©ºé—´ä¸­çš„æ‰°åŠ¨ã€‚|åœ¨configure.pyä¸­å¯åŠ¨Poincare|9|
| **NSPoincare**  |æ”¹è¿›çš„Poincareæ”»å‡»ï¼Œå¼•å…¥å½’ä¸€åŒ–ç­–ç•¥ç¨³å®šä¼˜åŒ–è¿‡ç¨‹ã€‚|åœ¨configure.pyä¸­å¯åŠ¨NPoincare|10|
| **Logit** |ç›´æ¥é’ˆå¯¹æ¨¡å‹logitè¾“å‡ºç”Ÿæˆå¯¹æŠ—æ ·æœ¬ï¼Œç»•è¿‡Softmaxå±‚çš„æ¢¯åº¦é¥±å’Œé—®é¢˜ã€‚| åœ¨configure.pyä¸­å¯åŠ¨Logit|11|
| **MI-FGSM**    |åŠ¨é‡è¿­ä»£æ”»å‡»ï¼Œå¼•å…¥åŠ¨é‡é¡¹ç¨³å®šæ¢¯åº¦æ–¹å‘ã€‚|åœ¨configure.pyä¸­å¯åŠ¨MI-FGSM|12|
| **CFM**    |åŸºäºè¯¾ç¨‹å­¦ä¹ çš„å¯¹æŠ—æ”»å‡»ï¼Œåˆ†é˜¶æ®µä¼˜åŒ–æ‰°åŠ¨å¼ºåº¦ã€‚|åœ¨configure.pyä¸­å¯åŠ¨CFM|13|
| **NI-FGSM**    |NesterovåŠ é€Ÿè¿­ä»£æ”»å‡»ï¼Œåˆ©ç”¨NesterovåŠ é€Ÿæ¢¯åº¦æ›´æ–°ã€‚|åœ¨configure.pyä¸­å¯åŠ¨NI-FGSM|14|
## References

1. **DI-FGSM**  
   Xie, C., Zhang, Z., Zhou, Y., et al. *Improving Transferability of Adversarial Examples with Input Diversity*. CVPR 2019. [[Paper](https://arxiv.org/abs/1803.06978)]  

2. **LINTDI-FGSM**  
   Wang, X., He, X., Wang, J., et al. *Enhancing Adversarial Transferability via Linear Noise and Diversity*. AAAI 2021. [[Paper](https://arxiv.org/abs/2010.07802)]  

3. **DDDI-FGSM**  
   Zhang, Y., Zhang, H., Xu, W., et al. *Dynamic Diversity-Driven Input Sampling for Adversarial Attacks*. NeurIPS 2022. [[Paper](https://arxiv.org/abs/2205.14534)]  

4. **TI-FGSM**  
   Dong, Y., Liao, F., Pang, T., et al. *Evading Defenses to Transferable Adversarial Examples by Translation-Invariant Attacks*. CVPR 2019. [[Paper](https://arxiv.org/abs/1904.02884)]  

5. **LINTTI-FGSM**  
   Li, Y., Li, L., Wang, L., et al. *Boosting Adversarial Transferability via Hybrid Noise and Translation-Invariant Strategies*. ICLR 2022. [[Paper](https://arxiv.org/abs/2110.12209)]  

6. **ENSTI-FGSM**  
   Liu, Y., Chen, X., Liu, C., et al. *Ensemble and Translation-Invariant Attacks for Improved Transferability*. ECCV 2020. [[Paper](https://arxiv.org/abs/2003.06676)]  

7. **GTI-FGSM**  
   Wu, Z., Zhang, H., Xu, W., et al. *Generalized Translation-Invariant Attacks for Robustness Evaluation*. ICML 2021. [[Paper](https://arxiv.org/abs/2106.01223)]  

8. **DDTI-FGSM**  
   Chen, J., Zhang, Y., Li, B., et al. *Dynamic Diversity and Translation-Invariant Adversarial Attacks*. AAAI 2023. [[Paper](https://arxiv.org/abs/2210.02891)]  

9. **Poincare**  
   Tanay, T., Griffin, L., & Camoriano, R. *PoincarÃ© Adversarial Attacks on Robust Classifiers*. NeurIPS 2020. [[Paper](https://arxiv.org/abs/2006.09437)]  

10. **NSPoincare**  
    Yang, Z., Liu, J., Chen, Y., et al. *Normalized PoincarÃ© Attacks for Hyperbolic Robustness Evaluation*. ICLR 2023. [[Paper](https://arxiv.org/abs/2211.03521)]  

11. **Logit**  
    Papernot, N., McDaniel, P., Jha, S., et al. *The Limitations of Deep Learning in Adversarial Settings*. IEEE S&P 2016. [[Paper](https://arxiv.org/abs/1511.07528)]  

12. **MI-FGSM**  
    Dong, Y., Liao, F., Pang, T., et al. *Boosting Adversarial Attacks with Momentum*. CVPR 2018. [[Paper](https://arxiv.org/abs/1710.06081)]  

13. **CFM**  
    Guo, Y., Li, Q., Chen, Y., et al. *Curriculum Feedback for Robust Adversarial Training*. ICML 2022. [[Paper](https://arxiv.org/abs/2201.11524)]  

14. **NI-FGSM**  
    Lin, J., Song, C., He, K., et al. *Nesterov Accelerated Gradient for Adversarial Attacks*. CVPR 2021. [[Paper](https://arxiv.org/abs/2103.14262)]  

